{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cea95b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2cb87b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold, learning_curve, KFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "# classification models\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "# evaluation metrics\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_selection import mutual_info_classif, f_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74cceb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('players_feats.csv')\n",
    "train = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e388f2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "031687d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1426 entries, 0 to 1425\n",
      "Columns: 132 entries, map_id to map_name_y\n",
      "dtypes: float64(80), int64(50), object(2)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "result = pd.merge(train, data, on=['map_id'])\n",
    "result.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e6675f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "team1_df = result[:][::2]\n",
    "team2_df = result[:][1::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c8d57db",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.merge(team1_df, team2_df, on=['map_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87cc11c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 713 entries, 0 to 712\n",
      "Columns: 263 entries, map_id to map_name_y_y\n",
      "dtypes: float64(160), int64(99), object(4)\n",
      "memory usage: 1.4+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.info()\n",
    "final_df.isnull().values.any().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e926e0eb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.dropna(inplace=True)\n",
    "final_df.isnull().values.any().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fac6284",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.get_dummies(final_df, columns = [\"map_name_x_x\"] , prefix_sep = \"_\",drop_first = True)\n",
    "final_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191382c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.DataFrame(final_df['who_win_x'])\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924c3648",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.drop(['map_id','team1_id_x','team1_id_y','team2_id_x','team2_id_y','who_win_x', 'who_win_y','map_name_x_y', 'map_name_y_x', 'map_name_y_y'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34fa572",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e148b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(final_df)\n",
    "X.info()\n",
    "X.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b3a718",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca554087",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler().fit(X)\n",
    "X_scaled = scaler.transform(X)\n",
    "selection = SelectKBest(score_func=f_classif, k=64).fit(X,y.values.ravel())\n",
    "X_new = selection.fit_transform(X, y.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e375249",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = pd.DataFrame(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3944f8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_hyperparams(model, parameters, x_train, y_train):\n",
    "    nfolds = 10\n",
    "    cross_val = StratifiedKFold(nfolds)\n",
    "    grid = GridSearchCV(model, parameters, cv=cross_val, refit=True, verbose=1, n_jobs=4)\n",
    "    grid.fit(x_train, y_train)\n",
    "    print(f'Accuracy : {grid.best_score_} with params {grid.best_estimator_}')\n",
    "    return grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6052f61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b409e657",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf = RandomForestClassifier(criterion='gini')\n",
    "print(X_train.shape, y_train.shape)\n",
    "rf_params = {\n",
    "    'n_estimators': [5, 15, 25],\n",
    "    'max_depth': [5, 15, 25],\n",
    "    'max_features': [16, 32, 64],\n",
    "    'max_leaf_nodes': [5, 10],\n",
    "    'bootstrap': [True]\n",
    "}\n",
    "best_rf = optimize_hyperparams(rf_clf, rf_params, X_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d90a583",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5cf510a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    x = X_train\n",
    "    y = y_train.values.ravel()\n",
    "    \n",
    "    max_depth = trial.suggest_int('xgb_max_depth', 2, 64, log=True)\n",
    "    max_leaves = trial.suggest_int('xgb_max_leaves', 5, 20)\n",
    "    n_estimators = trial.suggest_int('xgb_n_estimators', 100, 200)\n",
    "    learning_rate = trial.suggest_float('xgb_learning_rate', 0.001, 0.5)\n",
    "    gamma = trial.suggest_float('xgb_gamma', 1, 9)\n",
    "    \n",
    "    xgb_model = xgb.XGBClassifier(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        learning_rate=learning_rate,\n",
    "        max_leaves=max_leaves,\n",
    "        gamma=gamma\n",
    "    )\n",
    "    \n",
    "    \n",
    "#     rf_model = RandomForestClassifier(\n",
    "#         max_depth= max_depth,\n",
    "#         max_samples=max_samples,\n",
    "#         max_features=max_features,\n",
    "#         max_leaf_nodes=max_leaf_nodes,\n",
    "#         n_estimators=n_estimators,\n",
    "#         random_state=1337\n",
    "#     )\n",
    "    score = cross_val_score(xgb_model, x, y, cv=5).mean()\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb77959b",
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials = 100)\n",
    "\n",
    "trial = study.best_trial\n",
    "print(f'best score = {trial.value}')\n",
    "print(f'Best params: ')\n",
    "for key, value in trial.params.items():\n",
    "    print(f'{key} {value}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8eb5fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35294cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f793c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c972e38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BuildModel(best_alg, x_train, y_train, x_test, kf, ntrain, ntest, nclass, nfolds):\n",
    "    Xr_train = np.zeros((ntrain, nclass))\n",
    "    Xr_test = np.zeros((ntest, nclass))\n",
    "    tr_ind = np.arange(ntrain)\n",
    "    for i, (ttrain, ttest) in enumerate(kf.split(tr_ind)):\n",
    "        clf = best_alg\n",
    "        clf.fit(x_train.iloc[ttrain], y_train.iloc[ttrain])\n",
    "        sc = clf.score(x_train.iloc[ttest], y_train.iloc[ttest])\n",
    "        print(f'{i} accuracy {sc:.4f}')\n",
    "        Xr_train[ttest] = clf.predict_proba(x_train.iloc[ttest])\n",
    "        Xr_test += clf.predict_proba(x_test) / nfolds\n",
    "\n",
    "    return Xr_train, Xr_test\n",
    "\n",
    "\n",
    "def train_and_test_model(model, x_train, y_train, x_test, y_test, kf, ntrain, ntest, nclass, nfolds, labels):\n",
    "    pred_train, pred_test = BuildModel(model, x_train, y_train, x_test, kf, ntrain, ntest, nclass,\n",
    "                                       nfolds)\n",
    "    thresholds = np.linspace(0.01, 0.9, 100)\n",
    "    f1_sc = np.array([f1_score(y_train, pred_train[:, 1] > thr) for thr in thresholds])\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.plot(thresholds, f1_sc, linewidth=4)\n",
    "    plt.ylabel(\"F1 score\", fontsize=18)\n",
    "    plt.xlabel(\"Threshold\", fontsize=18)\n",
    "    best_lr = thresholds[f1_sc.argmax()]\n",
    "    show_accuracy(pred_train[:, 1], y_train, labels, best_lr, nclass)\n",
    "    show_accuracy(pred_test[:, 1], y_test, labels, best_lr, nclass)\n",
    "    \n",
    "\n",
    "def show_accuracy(Xr, y, labels, best, nclass):\n",
    "    pred = []\n",
    "    for x in Xr:\n",
    "        if x > best:\n",
    "            pred.append(1)\n",
    "        else:\n",
    "            pred.append(0)\n",
    "    print(f'pred = {pred}')\n",
    "    print(classification_report(y, pred, target_names=labels, digits=4, zero_division=True))\n",
    "    print(confusion_matrix(y, pred, labels=range(nclass)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cecd55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ntrain = X_train.shape[0]\n",
    "ntest = X_test.shape[0]\n",
    "nclass = 2\n",
    "NFOLDS = 10\n",
    "kf = KFold(n_splits=NFOLDS, random_state=1337, shuffle=True)\n",
    "labels = ['Team1_win', 'team2_win']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9a7a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f96df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_clf = xgb.XGBClassifier(max_depth=9, max_leaves=14, n_estimators=158, learning_rate=0.03, gamma=7.3)\n",
    "train_and_test_model(xgb_clf, X_train, y_train, X_test, y_test, kf, ntrain, ntest, nclass, NFOLDS, labels)\n",
    "\n",
    "# xgb_clf.fit(X_train, y_train)\n",
    "# rf_clf = RandomForestClassifier()\n",
    "# rf_clf.fit(X_train, y_train.values.ravel())\n",
    "# y_pred = xgb_clf.predict(X_test)\n",
    "# print(y_pred)\n",
    "# predictions = [value for value in y_pred]\n",
    "# print(predictions)\n",
    "# # evaluate predictions\n",
    "# fscore = f1_score(y_test, predictions)\n",
    "# print(\"Accuracy: %.2f%%\" % (fscore))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75202cb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d7cd92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
